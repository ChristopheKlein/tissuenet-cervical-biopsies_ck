{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from fastai.vision.all import *\n",
    "from utils.fastai_utils import train\n",
    "from utils.ml_model import get_avgmodel\n",
    "from utils.heatmap import process_one_tif\n",
    "from utils.train_patch import get_labeled_df, get_zero_df\n",
    "from utils.extract_feature_probsmap import get_probsmap_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta_path = '/home/fm/tissuenet/data/train_meta/train_metadata_eRORy1H.csv'  # train metadata path\n",
    "train_anno_path = '/home/fm/tissuenet/data/train_meta/train_annotations_lbzOVuS.csv' # train anno path\n",
    "train_label_path = '/home/fm/tissuenet/data/train_meta/train_labels.csv' # train label path\n",
    "\n",
    "tif_base_path = '/home/fm/tissuenet/data/train/tif/' # tif base path\n",
    "model_save_path = './models/' # path to save trained model\n",
    "heatmap_save_path = './heatmap/' # path to save heatmap(wsi pred result)\n",
    "\n",
    "patch_model_name = 'patch_model' # fastai model \n",
    "wsi_model_name = 'wsi_model.m' # wsi mechine learning model\n",
    "\n",
    "# base config\n",
    "read_level = 2  # we choose level 2 to read patch\n",
    "up_level = 3 # \n",
    "down_sample = 256 # downsample ratio is 256 compared with level 2 wsi size\n",
    "patch_numbers = 40 # we random choose 40 patchs from labeled 0 wsi\n",
    "infer_bs_size = 16 # we choose batchsize == 16 when inference\n",
    "\n",
    "lr=2e-2 # training learning rate\n",
    "epochs=10 # training epochs\n",
    "img_size=320 # image size\n",
    "bs_size=16 # training batch size\n",
    "model = densenet201 # model arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta = pd.read_csv(train_meta_path)\n",
    "train_anno = pd.read_csv(train_anno_path)\n",
    "train_label = pd.read_csv(train_label_path)\n",
    "zero_list = train_label[train_label['0'] == 1]['filename'].tolist()\n",
    "\n",
    "file_list = np.array(train_label['filename'].tolist())\n",
    "label_list = np.argmax(np.array(train_label)[:, 1:], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Get train dataframe\n",
    "\n",
    "We can get all patch to train with certain label from labeled patchs and 0 patchs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labeled_df = get_labeled_df(train_anno, [], read_level, img_size, base_path=tif_base_path)\n",
    "zero_df = get_zero_df(zero_list, [], read_level, down_sample, up_level, \n",
    "                 patch_numbers, img_size, base_path=tif_base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = labeled_df.append(zero_df)\n",
    "train_df = train_df.fillna(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Patch-level classification train\n",
    "\n",
    "train a densenet201 classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn = train(train_df, model, lr, epochs, img_size, bs_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "learn.model_dir = model_save_path\n",
    "learn.save(patch_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Generate heatmap\n",
    "\n",
    "we extract probsmaps from all train wsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(heatmap_save_path, exist_ok=True)\n",
    "model_path = os.path.join(model_save_path, patch_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsi_list = glob.glob(tif_base_path+'*.tif')\n",
    "\n",
    "for item in tqdm(wsi_list):\n",
    "    result = process_one_tif(item, down_sample, read_level, model_path, model, img_size, infer_bs_size)\n",
    "    np.save(heatmap_save_path+item.split('/')[-1].split('.')[0], result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: WSI-level classification train\n",
    "\n",
    "we employ a avg-mechine learning model to classification on wsi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = list(set([item.split(',')[0].split('/')[-1].split('.')[0] for item in train_df['region'].tolist()]))\n",
    "label = np.array([train_label[train_label['filename'] == name+'.tif'].iloc[0].tolist().index(1) - 1 for name in file_list])\n",
    "feature = np.array([get_probsmap_feature(heatmap_save_path+item+'.npy') for item in file_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_model = get_avgmodel(feature, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(avg_model, os.path.join(model_save_path, wsi_model_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
